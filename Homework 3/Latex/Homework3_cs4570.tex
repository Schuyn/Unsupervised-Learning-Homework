\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb, amsthm, bm}
\usepackage{mathtools}
\usepackage{geometry}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{color}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{multicol}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{pythonhighlight}
\usepackage{subcaption}

\geometry{margin=1in}

\pagestyle{fancy}
\fancyhf{}
\lhead{STAT 5244 -- Unsupervised Learning}
\rhead{HW3}
\cfoot{\thepage\ of \pageref{LastPage}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}

\renewcommand{\vec}[1]{\bm{#1}}

\usepackage{listings}
\lstset{
  basicstyle=\ttfamily\small,
  numbers=left,
  numberstyle=\tiny,
  stepnumber=1,
  numbersep=5pt,
  frame=single,
  breaklines=true,
  keywordstyle=\color{blue},
  commentstyle=\color{gray},
  stringstyle=\color{red},
  tabsize=4
}

% -------------------------------
% Start of the file
% -------------------------------
\begin{document}

\begin{center}
    {\Large \textbf{STAT 5244 -- Unsupervised Learning}}\\[6pt]
    \textbf{Homework 3}\\[6pt]
    Name: \underline{Chuyang Su} \quad UNI: \underline{cs4570}
\end{center}

\hrule
\vspace{1em}

% -------------------------------
% Problem 1
% -------------------------------
\section{Graphical Models.}

\subsection{Data Processing.}
The log return transformation was applied to the daily closing prices. The daily log return $r_t$ for a stock price $P_t$ was calculated as:
$$r_t = \ln(P_t) - \ln(P_{t-1})$$
This dataset of log returns, spanning 1,228 trading days, was used for all subsequent graphical model fitting.

\subsubsection{Descriptive Statistics}
The table below summarizes the descriptive statistics for the daily log returns.

\begin{table}[h!]
\centering
\caption{Descriptive Statistics of Daily Log Returns (Jan 2021 -- Present)}
\label{tab:descriptive_stats}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrrrrrrrrrrr}
\toprule
 & \texttt{AAPL} & \texttt{AMZN} & \texttt{BAC} & \texttt{CVX} & \texttt{GOOGL} & \texttt{JNJ} & \texttt{JPM} & \texttt{KO} & \texttt{META} & \texttt{MSFT} & \texttt{NVDA} & \texttt{PFE} & \texttt{PG} & \texttt{WMT} & \texttt{XOM} \\
\midrule
Count & 1228.00 & 1228.00 & 1228.00 & 1228.00 & 1228.00 & 1228.00 & 1228.00 & 1228.00 & 1228.00 & 1228.00 & 1228.00 & 1228.00 & 1228.00 & 1228.00 & 1228.00 \\
Mean ($\times 10^{-3}$) & 0.63 & 0.27 & 0.53 & 0.64 & 1.02 & 0.33 & 0.81 & 0.38 & 0.65 & 0.66 & \textbf{2.13} & -0.12 & 0.18 & 0.68 & 1.01 \\
Std ($\times 10^{-2}$) & 1.76 & 2.23 & 1.72 & 1.60 & 1.96 & 1.05 & 1.53 & 1.00 & 2.78 & 1.63 & \textbf{3.29} & 1.59 & 1.09 & 1.32 & 1.71 \\
Min & -0.097 & -0.151 & -0.117 & -0.086 & -0.100 & -0.079 & -0.078 & -0.072 & \textbf{-0.306} & -0.080 & -0.186 & -0.070 & -0.064 & -0.121 & -0.082 \\
Max & 0.143 & 0.127 & 0.081 & 0.085 & 0.097 & 0.060 & 0.109 & 0.046 & 0.209 & 0.097 & \textbf{0.218} & 0.103 & 0.042 & 0.091 & 0.062 \\
\bottomrule
\end{tabular}%
}
\end{table}

The data clearly demonstrates the risk-return trade-off. The semiconductor stock \texttt{NVDA} shows the highest average daily return ($\sim 0.213\%$) but also the highest volatility (Standard Deviation: $3.29\%$) and largest maximum single-day return ($\sim 21.8\%$). Conversely, consumer staples stocks like \texttt{KO} (Coca-Cola) and \texttt{PG} (P\&G) exhibit the lowest standard deviations ($\sim 1.0\%$), indicating high stability but lower returns. The largest single-day drop belongs to \texttt{META} (former FB) at $-30.6\%$.

\subsubsection{Time-Series Exploration}
The cumulative returns plot (Figure \ref{fig:cumulative_returns}) illustrates the differential performance across sectors over the analysis period.


\subsubsection{Correlation Analysis}
The correlation heatmap (Figure \ref{fig:correlation_heatmap}) reveals strong clustering of dependence among stocks within the same sector, which confirms the pervasive influence of systematic market risk.

\textbf{Key Observations from the Heatmap:}
\begin{itemize}
    \item \textbf{Strong Correlation (0.6+):} High-tech stocks (\texttt{AAPL}, \texttt{MSFT}, \texttt{AMZN}, \texttt{GOOGL}, \texttt{NVDA}) are tightly coupled (e.g., \texttt{MSFT-AMZN} at 0.66, \texttt{MSFT-GOOGL} at 0.65). Financials (\texttt{JPM-BAC} at 0.82) and Energy stocks (\texttt{CVX-XOM} at 0.86) exhibit the highest correlations, reflecting their singular dependence on industry-specific factors (e.g., oil price, interest rates).
    \item \textbf{Weak/Low Correlation (0.0-0.3):} Healthcare stocks (\texttt{JNJ}, \texttt{PFE}) show low correlation with most other stocks (e.g., \texttt{JNJ} vs. Tech stocks often below 0.2), confirming their defensive, counter-cyclical nature.
    \item \textbf{Negative Correlation:} A notable weak negative correlation exists between the pharmaceutical stock \texttt{JNJ} and the high-growth technology stock \texttt{NVDA} ($\sim -0.09$), suggesting an interesting divergence in their underlying risk drivers.
\end{itemize}

This preliminary analysis confirms the existence of strong, sector-specific dependencies, which the Graphical Lasso will aim to distill into a network of conditional dependencies.

\begin{figure}[h!]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/1a_cumulative_returns.png}
        \caption{Cumulative Log Returns of Selected Stocks (Jan 2021 - Present)}
        \label{fig:cumulative_returns}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/1a_correlation_heatmap.png}
        \caption{Correlation Heatmap of Daily Log Returns}
        \label{fig:correlation_heatmap}
    \end{minipage}
\end{figure}

\subsection{Graphical Lasso.}

Figure~\ref{fig:glasso_precision} shows the estimated precision matrices from both the Gaussian Graphical Lasso and the
nonparanormal (rank-based) Graphical Lasso. The two heatmaps are almost identical,
indicating that although individual stock returns are heavy-tailed, the dependence
structure is well approximated by a Gaussian copula. Consequently, both methods
recover essentially the same sparse conditional dependence network, suggesting that the
underlying structure is stable, low-dimensional, and largely driven by sector-level
factors.

The estimated graph highlights several strong conditional dependencies (e.g.,
AMZN--KO, JPM--GOOGL, WMT--BAC, NVDA--PFE) and a clear technology cluster
consisting of AAPL, MSFT, GOOGL, AMZN, and META. NVIDIA does not join this
cluster, likely due to its unusually strong and volatile performance during the sample
period, which weakens its partial correlations with the other technology stocks after
conditioning on the full set of variables.

The regularization parameter $\alpha$ was selected via cross-validated Gaussian
log-likelihood over a grid of 30 values spanning $\log_{10}(0.01)$ to
$\log_{10}(0.8)$. This criterion is appropriate for unsupervised graphical models, as
the validation likelihood measures generalization of the estimated precision matrix. The
optimal values were
\[
\alpha_{\text{Gaussian}} = 0.021287, \qquad
\alpha_{\text{Nonparanormal}} = 0.013528.
\]
For brevity, only the tuning curve for the Gaussian estimator is shown in
Figure~\ref{fig:glasso_cv_curve}.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{Figures/1b_glasso_precision_matrices.png}
    \caption{Gaphic Lasso Estimated Precision Matrices: Standard (Left) vs. Non-Parametric (Right)}
    \label{fig:glasso_precision}
\end{figure}

\begin{figure}[h!]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/1b_glasso_cv_curve.png}
        \caption{Cross-Validated Log-Likelihood Curve for Standard Graphical Lasso}
        \label{fig:glasso_cv_curve}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/1c_pc_tuning.png}
        \caption{Best Alpha Selection for PC Algorithm via BIC Score}
        \label{fig:pc_tuning}
    \end{minipage}
\end{figure}

\subsection{PC Algorithm.}

To determine the optimal regularization level for the PC algorithm, we evaluated the
Bayesian Information Criterion (BIC) across a range of significance thresholds
$$\alpha \in \{0.001,\,0.01,\,0.05,\,0.1,\,0.2\}.$$
The resulting BIC scores are shown in
Figure~\ref{fig:pc_tuning}. Although $\alpha = 0.05$ is
often used as a conventional threshold, the BIC curve indicates that the model achieves
its minimum score at $\alpha = 0.1$, implying that this level of sparsity provides the
best balance between model fit and complexity.

Based on this criterion, we select $\alpha = 0.1$ and construct the final directed graph
using the PC algorithm. The resulting structure is displayed in
Figure~\ref{fig:pc_graph}, which represents the learned
conditional independence relations and the corresponding Markov equivalence
class under this optimal parameter choice.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{Figures/1c_pc_graph.png}
    \caption{Best PC Algorithm Graph at $\alpha = 0.1$}
    \label{fig:pc_graph}
\end{figure}

\subsection{Comparison and Interpretation.}
The learned structure from Figure~\ref{fig:pc_graph} displays a clear pattern:
technology stocks exhibit substantially richer and more directional dependency
relationships compared to the other sectors. For example, MSFT appears as a
child of all technology names, including AAPL, GOOGL, NVDA, AMZN and META,
indicating that its conditional distribution depends structurally on multiple
peers within the same sector. In contrast, NVDA and GOOGL share an undirected
edge but act as parents to all other surrounding nodes, placing them in more central
positions within the technology cluster. These findings are consistent with the
results from part (b), in which the precision matrices also implied a tightly
connected technology block.

Other sectors exhibit markedly more isolated behavior. For instance, in the
energy sector, XOM is connected only to CVX, and once CVX is conditioned on,
XOM becomes conditionally independent of all other stocks in the universe. This
highlights both the internal coherence of the energy sector and its relative
independence from the remaining market, which are consistent with common sense.

An interesting contrast emerges when comparing the PC graph with the precision
matrices from part (b). Pairs such as KO--AMZN and JPM--GOOGL exhibit strong
partial correlations under the Gaussian and nonparanormal graphical lasso, yet
no direct edge appears between them in the PC graph. This difference reflects
the distinct logics of the two models: graphical lasso identifies pairwise
partial correlations, while the PC algorithm searches for a directed acyclic
graph that satisfies a complete set of conditional independence relations. As a
result, some associations are represented not by direct edges but by indirect
paths---for example, KO connects to AMZN through AAPL or WMT. This is also
consistent with economic intuition, as consumer staples and mega-cap technology
firms often share indirect market linkages through broader macro or demand
channels.

\subsection{Granger Causal Graphical Model.}
\begin{table}[H]
\centering
\caption{Top 10 Significant Granger Causal Relationships}
\begin{tabular}{lccc}
\toprule
\textbf{Cause (X)} & \textbf{Effect (Y)} & \textbf{P-value} & \textbf{Lag} \\
\midrule
META & AMZN & 0.000002 & 1 \\
AAPL & JPM  & 0.000089 & 4 \\
WMT  & PG   & 0.000165 & 3 \\
AAPL & META & 0.000319 & 4 \\
WMT  & KO   & 0.000415 & 1 \\
MSFT & PG   & 0.000963 & 4 \\
AAPL & MSFT & 0.001364 & 3 \\
BAC  & AAPL & 0.001686 & 2 \\
AAPL & AMZN & 0.002355 & 4 \\
AAPL & BAC  & 0.002579 & 3 \\
\bottomrule
\end{tabular}
\end{table}

To evaluate the stability of the Granger causality model, we performed a
hyperparameter sweep over significance levels $\alpha \in \{0.01, 0.05, 0.1\}$ and
maximum lags $\{1,3,5,7,10\}$. The resulting edge counts and graph densities are
summarized in Figure~\ref{fig:granger_tuning}. The heatmaps show a clear monotonic
pattern: both the number of detected causal edges and the overall graph density grow
rapidly as either $\alpha$ or the maximum lag increases. This behavior reflects the
well-known sensitivity of Granger causality tests to both noise and multiple
comparisons, particularly when applied to high-volatility financial return data.

Because interpretable causal networks should remain reasonably sparse, we selected
$\alpha = 0.05$ and a maximum lag of 5 as a compromise between sparsity and
statistical power. However, even under this moderate configuration the resulting
Granger graph still contains 52 significant edges (density = 0.248), which is far more
dense than the structures obtained in parts (b) and (c). This indicates that the
Granger model captures a substantial amount of noise rather than stable structural
dependencies.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{Figures/1e_granger_tuning.png}
    \caption{Best PC Algorithm Graph at $\alpha = 0.1$}
    \label{fig:granger_tuning}
\end{figure}

\end{document}